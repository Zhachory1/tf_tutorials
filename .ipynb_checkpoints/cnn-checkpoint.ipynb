{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Guide to TF Layers: Building a Convolutional Neural Network\n",
    "\n",
    "I am doing a tutorial from the tensorflow website for CNNs. The url for this tutorial can be found [here](https://www.tensorflow.org/tutorials/layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Tensorflow:', '1.1.0')\n",
      "(u'Python Version:', '2.7.14 |Anaconda, Inc.| (default, Dec  7 2017, 17:05:42) \\n[GCC 7.2.0]')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import load_iris,fetch_mldata\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "print(\"Tensorflow:\", tf.__version__)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Our application logic will be added here\n",
    "# if __name__ == \"__main__\":\n",
    "#   tf.app.run()\n",
    "\n",
    "import sys\n",
    "print(\"Python Version:\", sys.version)\n",
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using the estimator API to construct a model function to hold my model. It's a basic 2 layer cnn conv-pool model with a fully conected layer up top (with some dropout). I use ReLu activations for everything except for predictions, which uses softmax. \n",
    "\n",
    "If it is in predict mode, I just send back the estimator spec as is. If it's training, I also add the optimizer and training operation in the as well. I am using Adam optimization with a cross entropy loss functionwith an lr of 0.001 with the default alpha (0.9), beta (0.999), and episilon(1e-8).\n",
    "\n",
    "Finally, if it's eval mode, I add the accuracy onto it (since it's a classifaction problem). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    flat = tf.reshape(pool2, [-1, 7*7*64])\n",
    "    dense = tf.layers.dense(inputs=flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.5, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1), # For PREDICT and EVAL\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    \n",
    "    eval_op = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_op)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some MNIST data into here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "test_data = mnist.test.images\n",
    "test_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to create the actual estimator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {}\n"
     ]
    }
   ],
   "source": [
    "mnist_clf = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"./cnn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep an eye on the training, we are going to attach a logging hook onto it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors_to_log = {\"probabilities\": \"softmax\"}\n",
    "log_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train this sucker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.19398, step = 2\n",
      "INFO:tensorflow:global_step/sec: 3.63025\n",
      "INFO:tensorflow:loss = 0.121737, step = 102 (27.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.42828\n",
      "INFO:tensorflow:loss = 0.102046, step = 202 (29.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.41559\n",
      "INFO:tensorflow:loss = 0.0784528, step = 302 (29.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.44141\n",
      "INFO:tensorflow:loss = 0.0832209, step = 402 (29.058 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.00000217  0.99898368  0.00009762  0.00000131  0.00081133  0.00000083\n",
      "   0.00000707  0.00000243  0.00007146  0.00002212]\n",
      " [ 0.          0.          0.          0.00027576  0.0000003   0.99964869\n",
      "   0.00000167  0.00000006  0.00000684  0.00006659]\n",
      " [ 0.          0.00000013  0.00000002  0.          0.99999893  0.\n",
      "   0.00000006  0.00000082  0.          0.        ]\n",
      " [ 0.99997711  0.00000001  0.00001993  0.          0.          0.\n",
      "   0.00000001  0.0000029   0.00000003  0.00000004]\n",
      " [ 0.00000001  0.00000009  0.00000007  0.          0.99999917  0.          0.\n",
      "   0.00000043  0.00000003  0.0000002 ]\n",
      " [ 0.00000904  0.99974936  0.00013179  0.00000106  0.00006725  0.0000002\n",
      "   0.00000235  0.00000638  0.00003202  0.00000047]\n",
      " [ 0.00026637  0.00008596  0.0046131   0.00023635  0.00001261  0.00000913\n",
      "   0.00000002  0.99296075  0.00000658  0.00180912]\n",
      " [ 0.          0.00000001  0.00000001  0.00003012  0.00000003  0.99989212\n",
      "   0.00000535  0.          0.00006073  0.00001163]\n",
      " [ 0.00000071  0.99993503  0.00000111  0.00000039  0.00004885  0.00000044\n",
      "   0.00000393  0.00000058  0.00000868  0.00000021]\n",
      " [ 0.00627203  0.07189474  0.40588719  0.0033645   0.00248081  0.00231299\n",
      "   0.48485366  0.00000616  0.02288902  0.00003899]\n",
      " [ 0.00000085  0.00000141  0.00029165  0.00001934  0.00000033  0.          0.\n",
      "   0.99965751  0.00000721  0.00002171]\n",
      " [ 0.96454519  0.00006256  0.02320448  0.00091598  0.00007518  0.00093068\n",
      "   0.00254144  0.00081549  0.00024957  0.00665939]\n",
      " [ 0.00000028  0.00002156  0.00001281  0.00023339  0.00001116  0.00595418\n",
      "   0.00001178  0.00000028  0.99375266  0.00000191]\n",
      " [ 0.00001843  0.00001104  0.00004525  0.82347548  0.00011696  0.10439242\n",
      "   0.00000865  0.00017051  0.00301847  0.06874283]\n",
      " [ 0.00011726  0.00216407  0.99720663  0.00006013  0.00000003  0.00000008\n",
      "   0.00000026  0.0004097   0.00004174  0.00000014]\n",
      " [ 0.00000037  0.00000071  0.00000011  0.0009727   0.0000094   0.99842167\n",
      "   0.00000257  0.00000085  0.00003491  0.00055662]\n",
      " [ 0.00010995  0.00128476  0.00084238  0.00143044  0.00853144  0.0000057\n",
      "   0.00000035  0.01463371  0.06429873  0.90886247]\n",
      " [ 0.00000155  0.00001895  0.00002373  0.0003701   0.0000068   0.00012835\n",
      "   0.00000776  0.00000065  0.99943632  0.00000575]\n",
      " [ 0.00000045  0.99977177  0.00001491  0.00000022  0.00020177  0.00000167\n",
      "   0.00000166  0.00000278  0.00000347  0.00000133]\n",
      " [ 0.00005296  0.00015428  0.00008545  0.00000016  0.99949872  0.00000005\n",
      "   0.00000836  0.00008976  0.00000415  0.00010614]\n",
      " [ 0.000508    0.00765991  0.10477538  0.81740165  0.00029311  0.04676918\n",
      "   0.00075077  0.01222186  0.00364756  0.00597253]\n",
      " [ 0.99990678  0.          0.00001633  0.00000005  0.00000032  0.00000018\n",
      "   0.00001323  0.00000096  0.00000082  0.00006122]\n",
      " [ 0.00000001  0.00000021  0.0000491   0.99994564  0.          0.          0.\n",
      "   0.00000025  0.00000405  0.00000071]\n",
      " [ 0.00147726  0.00005465  0.00670189  0.00009322  0.7736128   0.00016426\n",
      "   0.0036224   0.00039699  0.00050418  0.21337229]\n",
      " [ 0.00015514  0.00779955  0.02342048  0.00016666  0.95962048  0.00005935\n",
      "   0.00006057  0.00844177  0.00020166  0.00007427]\n",
      " [ 0.99993992  0.00000002  0.00001971  0.          0.          0.00000002\n",
      "   0.00003878  0.00000007  0.0000007   0.00000069]\n",
      " [ 0.00000032  0.00000001  0.00000045  0.00157922  0.00000008  0.98906541\n",
      "   0.00000062  0.00000977  0.00002795  0.0093161 ]\n",
      " [ 0.99967825  0.00000001  0.00006157  0.00000155  0.          0.00001258\n",
      "   0.0000117   0.00000006  0.00012012  0.00011421]\n",
      " [ 0.00000003  0.          0.00000007  0.00002448  0.00000135  0.00000088\n",
      "   0.          0.00000135  0.00008914  0.9998827 ]\n",
      " [ 0.00841873  0.0006891   0.00945026  0.06673004  0.01006822  0.01064926\n",
      "   0.00109561  0.00208998  0.57361716  0.31719163]\n",
      " [ 0.00000001  0.00001464  0.99997175  0.00001039  0.          0.          0.\n",
      "   0.00000311  0.00000013  0.        ]\n",
      " [ 0.00008426  0.00007366  0.0000489   0.00100041  0.00005185  0.98513341\n",
      "   0.00474364  0.00000036  0.00841146  0.00045214]\n",
      " [ 0.0000145   0.00001056  0.00001348  0.0000002   0.00004239  0.00004895\n",
      "   0.99986744  0.          0.00000248  0.00000002]\n",
      " [ 0.          0.00000001  0.00000052  0.99999833  0.          0.0000002\n",
      "   0.          0.00000001  0.00000055  0.00000042]\n",
      " [ 0.00000005  0.00000657  0.00003093  0.99988174  0.00000004  0.00004251\n",
      "   0.00000001  0.00000531  0.00000314  0.0000296 ]\n",
      " [ 0.00000861  0.00000417  0.0003059   0.99957877  0.00000012  0.00002753\n",
      "   0.0000001   0.00000696  0.00003752  0.00003034]\n",
      " [ 0.00000023  0.99994493  0.00001276  0.00000002  0.00003811  0.00000006\n",
      "   0.00000073  0.0000028   0.00000018  0.00000008]\n",
      " [ 0.00001773  0.00681621  0.98908615  0.00272241  0.00000279  0.00000069\n",
      "   0.00000115  0.00004555  0.00129098  0.00001628]\n",
      " [ 0.00000021  0.00000191  0.00000283  0.00000024  0.999843    0.00000054\n",
      "   0.00000021  0.00004352  0.00000212  0.00010527]\n",
      " [ 0.00000206  0.00004577  0.00000063  0.00397635  0.00024737  0.98487955\n",
      "   0.00001345  0.00008165  0.01062348  0.00012971]\n",
      " [ 0.00000002  0.00000028  0.00000015  0.00000001  0.00000017  0.00002268\n",
      "   0.9999758   0.          0.00000084  0.        ]\n",
      " [ 0.00003803  0.90121633  0.00184511  0.00264428  0.00047101  0.00017523\n",
      "   0.00002634  0.00004017  0.09326015  0.00028339]\n",
      " [ 0.00000745  0.00000121  0.00000569  0.          0.99993026  0.00000004\n",
      "   0.00004917  0.00000497  0.00000087  0.00000033]\n",
      " [ 0.00073713  0.00001794  0.00013014  0.00000012  0.9967609   0.00000937\n",
      "   0.00008818  0.00222749  0.00000737  0.00002141]\n",
      " [ 0.00000004  0.00000007  0.00000004  0.00676144  0.00000018  0.99290848\n",
      "   0.00000529  0.00000003  0.00013946  0.00018502]\n",
      " [ 0.00000281  0.00000108  0.00000223  0.00000032  0.00015182  0.00000074\n",
      "   0.          0.9979741   0.00000027  0.00186667]\n",
      " [ 0.99555212  0.00000002  0.00093517  0.00000558  0.00000018  0.0000946\n",
      "   0.0014333   0.00000148  0.00011795  0.00185954]\n",
      " [ 0.00000051  0.00001087  0.00115359  0.00003754  0.0000001   0.00000001\n",
      "   0.          0.99867249  0.00000088  0.00012414]\n",
      " [ 0.99196953  0.00001097  0.00728526  0.00003772  0.00001519  0.00003497\n",
      "   0.00001017  0.00005362  0.00051122  0.00007137]\n",
      " [ 0.0000001   0.00000042  0.00000036  0.          0.99999452  0.00000006\n",
      "   0.00000237  0.0000015   0.00000055  0.00000003]\n",
      " [ 0.00000424  0.          0.00000001  0.          0.00000004  0.00000062\n",
      "   0.99999499  0.          0.0000001   0.00000001]\n",
      " [ 0.99851698  0.00000004  0.0000033   0.00000563  0.          0.00000334\n",
      "   0.00000015  0.00000107  0.00000196  0.00146754]\n",
      " [ 0.0000115   0.00048869  0.00038999  0.00028531  0.00445199  0.00184636\n",
      "   0.00009336  0.0000572   0.99226719  0.00010837]\n",
      " [ 0.00000045  0.00000018  0.00006545  0.00001745  0.00000001  0.00000009\n",
      "   0.          0.99989462  0.00000001  0.00002184]\n",
      " [ 0.00000003  0.00000083  0.0000014   0.99996662  0.00000002  0.0000205\n",
      "   0.          0.00000018  0.000004    0.00000646]\n",
      " [ 0.00000002  0.0000006   0.00000242  0.99988925  0.00000054  0.00004302\n",
      "   0.          0.00000015  0.00000807  0.00005591]\n",
      " [ 0.00000004  0.0000042   0.00003485  0.99988937  0.00000009  0.00001121\n",
      "   0.          0.00000014  0.00003891  0.00002127]\n",
      " [ 0.99265999  0.00009715  0.00622533  0.0000001   0.00002969  0.00000063\n",
      "   0.00003717  0.0009106   0.00001647  0.00002291]\n",
      " [ 0.00000018  0.05502714  0.94483662  0.00011901  0.00000001  0.00000001\n",
      "   0.00000003  0.00000583  0.00001093  0.00000021]\n",
      " [ 0.00021121  0.00000587  0.00001491  0.00000012  0.0012175   0.00005727\n",
      "   0.99848109  0.00000022  0.00000978  0.00000212]\n",
      " [ 0.00014087  0.00004048  0.00162683  0.00894363  0.00004589  0.00004456\n",
      "   0.00000163  0.00008863  0.89293623  0.09613125]\n",
      " [ 0.00013816  0.00292498  0.00126577  0.0016966   0.87021005  0.00405099\n",
      "   0.00042171  0.00037419  0.00059658  0.11832102]\n",
      " [ 0.00001638  0.00001821  0.00004229  0.08476406  0.00011251  0.00771542\n",
      "   0.00000037  0.00000535  0.00199738  0.90532809]\n",
      " [ 0.00031966  0.01939417  0.0527809   0.01332911  0.00260653  0.00042329\n",
      "   0.000373    0.00031645  0.90911967  0.00133724]\n",
      " [ 0.57831472  0.00009367  0.38862869  0.01079435  0.00000074  0.00014842\n",
      "   0.00008066  0.00303436  0.01058878  0.00831555]\n",
      " [ 0.00000439  0.00000943  0.00001356  0.00000038  0.99874997  0.00003344\n",
      "   0.00000802  0.00012357  0.00000254  0.00105467]\n",
      " [ 0.00435375  0.00003634  0.0001367   0.00000227  0.00012369  0.00010588\n",
      "   0.99523193  0.00000075  0.00000605  0.0000027 ]\n",
      " [ 0.00004459  0.00004372  0.00179771  0.03379408  0.00000429  0.00103347\n",
      "   0.00020942  0.00000103  0.96304196  0.00002971]\n",
      " [ 0.00000004  0.00000004  0.00000152  0.00027595  0.00000685  0.00000063\n",
      "   0.          0.00000102  0.00017482  0.99953914]\n",
      " [ 0.00017732  0.00063925  0.004191    0.1666798   0.00705783  0.06298307\n",
      "   0.00200903  0.00267627  0.56453013  0.18905641]\n",
      " [ 0.          0.00000047  0.00000139  0.99999642  0.00000001  0.00000004\n",
      "   0.          0.00000045  0.00000112  0.00000004]\n",
      " [ 0.99989927  0.          0.00000233  0.          0.          0.00000012\n",
      "   0.00009635  0.00000007  0.00000027  0.00000156]\n",
      " [ 0.00153373  0.00012408  0.00004201  0.00000939  0.0002039   0.00257302\n",
      "   0.99100262  0.00000317  0.00445136  0.00005666]\n",
      " [ 0.00000017  0.0000019   0.00000085  0.00000005  0.00000812  0.00000001\n",
      "   0.          0.99998653  0.00000001  0.00000237]\n",
      " [ 0.00000025  0.99977404  0.00001197  0.00000096  0.00017654  0.00000113\n",
      "   0.00000179  0.00000079  0.00003027  0.0000022 ]\n",
      " [ 0.00000406  0.99897718  0.00005027  0.00000611  0.00001624  0.00000048\n",
      "   0.00000046  0.00001652  0.00090077  0.00002796]\n",
      " [ 0.00000001  0.00000032  0.00000286  0.00015042  0.00007807  0.00001018\n",
      "   0.          0.00000103  0.00006954  0.99968767]\n",
      " [ 0.00000008  0.00000057  0.00000694  0.00088865  0.00000222  0.00001394\n",
      "   0.00000016  0.00000002  0.99898177  0.00010564]\n",
      " [ 0.0000001   0.00006052  0.00002759  0.99978715  0.00000006  0.00010813\n",
      "   0.          0.00000033  0.00000293  0.00001318]\n",
      " [ 0.00000001  0.          0.00000004  0.00004641  0.00000217  0.00000001\n",
      "   0.          0.00000183  0.00001253  0.99993706]\n",
      " [ 0.          0.00000001  0.00000001  0.00132351  0.0000002   0.99866402\n",
      "   0.00000146  0.          0.00000867  0.00000215]\n",
      " [ 0.          0.          0.00000003  1.          0.          0.00000004\n",
      "   0.          0.          0.          0.00000005]\n",
      " [ 0.          0.          0.          0.00000099  0.          0.99999702\n",
      "   0.00000014  0.          0.00000149  0.00000037]\n",
      " [ 0.00000001  0.00000007  0.00000028  0.00012732  0.00026278  0.00000021\n",
      "   0.          0.00000088  0.0002264   0.99938202]\n",
      " [ 0.00000005  0.00000001  0.00000738  0.00000089  0.00000003  0.00000132\n",
      "   0.00000023  0.00000002  0.99998438  0.00000567]\n",
      " [ 0.          0.          0.          0.00000019  0.          0.9999392\n",
      "   0.00000045  0.          0.00003307  0.000027  ]\n",
      " [ 0.00021591  0.00001438  0.00027668  0.00156926  0.00131809  0.00002579\n",
      "   0.00000911  0.00372424  0.00190433  0.99094218]\n",
      " [ 0.00000074  0.00001707  0.00009287  0.9990074   0.00000003  0.00082907\n",
      "   0.00000005  0.00000109  0.00004698  0.00000474]\n",
      " [ 0.          0.00000014  0.00000758  0.9999913   0.          0.00000033\n",
      "   0.          0.00000046  0.00000008  0.00000001]\n",
      " [ 0.00000913  0.99945956  0.00006001  0.00000122  0.000331    0.00000094\n",
      "   0.00007523  0.00001279  0.00004994  0.00000011]\n",
      " [ 0.00058213  0.00058257  0.04982733  0.05058066  0.00029933  0.00056253\n",
      "   0.00000562  0.44023705  0.00067354  0.45664933]\n",
      " [ 0.00004098  0.99628073  0.00016505  0.0000064   0.00101698  0.0000113\n",
      "   0.00002684  0.00001979  0.00242646  0.00000542]\n",
      " [ 0.          0.00000014  0.00001421  0.99998426  0.          0.00000102\n",
      "   0.          0.00000001  0.0000003   0.00000003]\n",
      " [ 0.00000245  0.00000046  0.00000055  0.00054569  0.00000028  0.99933738\n",
      "   0.00000596  0.00000013  0.00000153  0.00010541]\n",
      " [ 0.00000008  0.00002835  0.0000227   0.00000777  0.00000049  0.00000041\n",
      "   0.          0.99988854  0.0000001   0.00005159]\n",
      " [ 0.00001559  0.00000894  0.00001147  0.00001003  0.99101627  0.00001246\n",
      "   0.00000296  0.00028773  0.00002571  0.00860881]\n",
      " [ 0.99760371  0.00000238  0.00237014  0.00000042  0.00000078  0.00000015\n",
      "   0.0000056   0.00000102  0.00000399  0.00001182]\n",
      " [ 0.00004599  0.00004419  0.00004964  0.00005771  0.00001644  0.00538531\n",
      "   0.9940958   0.00000006  0.00030463  0.00000019]\n",
      " [ 0.99860841  0.00000001  0.00025437  0.00000009  0.00000012  0.00000049\n",
      "   0.00000068  0.00107483  0.00004564  0.00001533]\n",
      " [ 0.00001367  0.00063788  0.00034538  0.00167604  0.00140117  0.00099841\n",
      "   0.00006917  0.00000294  0.99477297  0.00008237]] (151.324 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 501 into ./cnn_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0340165.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f64741b4750>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "mnist_clf.train(input_fn=train_input_fn, steps=500, hooks=[log_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-03-24-19:59:52\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/model.ckpt-501\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-24-20:00:00\n",
      "INFO:tensorflow:Saving dict for global step 501: accuracy = 0.9825, global_step = 501, loss = 0.0527337\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "{'loss': 0.052733701, 'global_step': 501, u'accuracy': 0.98250002}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": test_data},\n",
    "    y=test_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_result = mnist_clf.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
